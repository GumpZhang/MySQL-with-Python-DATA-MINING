{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T02:49:38.266185Z",
     "start_time": "2020-01-10T02:49:36.664646Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T02:50:02.243689Z",
     "start_time": "2020-01-10T02:50:02.224775Z"
    },
    "code_folding": [
     0,
     12
    ]
   },
   "outputs": [],
   "source": [
    "def calculate_test_statistic(ts):\n",
    "    \"\"\"Calculate the test statistic defined by being\n",
    "       the top zscore in the timeseries.\n",
    "    Args:\n",
    "        ts (list or np.array): The timeseries to compute the test statistic.\n",
    "    Returns:\n",
    "        tuple(int, float): The index of the top zscore and the value of the top zscore.\n",
    "    \"\"\"\n",
    "    zscores = abs(stats.zscore(ts, ddof=1))\n",
    "    max_idx = np.argmax(zscores)\n",
    "    return max_idx, zscores[max_idx]\n",
    "\n",
    "def calculate_critical_value(ts, alpha):\n",
    "    \"\"\"Calculate the critical value with the formula given for example in\n",
    "    https://en.wikipedia.org/wiki/Grubbs%27_test_for_outliers#Definition\n",
    "    Args:\n",
    "        ts (list or np.array): The timeseries to compute the critical value.\n",
    "        alpha (float): The significance level.\n",
    "    Returns:\n",
    "        float: The critical value for this test.\n",
    "    \"\"\"\n",
    "    size   = len(ts)\n",
    "    t_dist = stats.t.ppf(1 - alpha / (2 * size), size - 2)\n",
    "    \n",
    "    numerator   = (size - 1) * t_dist\n",
    "    denominator = np.sqrt(size ** 2 - size * 2 + size * t_dist ** 2)\n",
    "\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T02:50:08.671122Z",
     "start_time": "2020-01-10T02:50:08.650997Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def seasonal_esd(ts, seasonality=None, hybrid=False, max_anomalies=10, alpha=0.05):\n",
    "    \"\"\"Compute the Seasonal Extreme Studentized Deviate of a time series. \n",
    "       The steps taken are first to to decompose the timeseries into STL \n",
    "       decomposition (trend, seasonality, residual). Then, calculate \n",
    "       the Median Absolute Deviate (MAD) if hybrid (otherwise the median) \n",
    "       and perform a regular ESD test on the residual, which we calculate as:\n",
    "                        R = ts - seasonality - MAD or median\n",
    "       \n",
    "       Note: The statsmodel library requires a seasonality to compute the STL\n",
    "       decomposition, hence the parameter seasonality. If none is given,\n",
    "       then it will automatically be calculated to be 20% of the total\n",
    "       timeseries.\n",
    "    Args:\n",
    "        ts (list or np.array): The timeseries to compute the ESD.\n",
    "        seasonality (int): Number of time points for a season.\n",
    "        hybrid (bool): See Twitter's research paper for difference.\n",
    "        max_anomalies (int): The number of times the Grubbs' Test will be applied to the ts.\n",
    "        alpha (float): The significance level.\n",
    "    Returns:\n",
    "        list int: The indices of the anomalies in the timeseries.\n",
    "    \"\"\"\n",
    "    ts = np.array(ts)\n",
    "    seasonal = seasonality or int(0.2 * len(ts)) # Seasonality is 20% of the ts if not given.\n",
    "    decomp   = sm.tsa.seasonal_decompose(ts, freq=seasonal)\n",
    "    if hybrid:\n",
    "        mad      = np.median(np.abs(ts - np.median(ts)))\n",
    "        residual = ts - decomp.seasonal - mad\n",
    "    else:\n",
    "        residual = ts - decomp.seasonal - np.median(ts)\n",
    "    outliers = esd(residual, max_anomalies=max_anomalies, alpha=alpha)\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T02:50:13.034110Z",
     "start_time": "2020-01-10T02:50:13.016191Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def esd(timeseries, max_anomalies=10, alpha=0.05):\n",
    "    \"\"\"Compute the Extreme Studentized Deviate of a time series. \n",
    "       A Grubbs Test is performed max_anomalies times with the caveat \n",
    "       that each time the top value is removed. For more details visit\n",
    "       http://www.itl.nist.gov/div898/handbook/eda/section3/eda35h3.htm\n",
    "    Args:\n",
    "        timeseries (list or np.array): The timeseries to compute the ESD.\n",
    "        max_anomalies (int): The number of times the Grubbs' Test will be applied to the ts.\n",
    "        alpha (float): The significance level.\n",
    "    Returns:\n",
    "        list int: The indices of the anomalies in the timeseries.\n",
    "    \"\"\"\n",
    "    ts = np.copy(np.array(timeseries))\n",
    "    test_statistics = []\n",
    "    total_anomalies = -1\n",
    "    for curr in range(max_anomalies):\n",
    "        test_idx, test_val = calculate_test_statistic(ts)\n",
    "        critical_value     = calculate_critical_value(ts, alpha)\n",
    "        if test_val > critical_value:\n",
    "            total_anomalies = curr\n",
    "        test_statistics.append(test_idx)\n",
    "        ts = np.delete(ts, test_idx)\n",
    "    anomalous_indices = test_statistics[:total_anomalies + 1]\n",
    "    return anomalous_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T02:51:58.961742Z",
     "start_time": "2020-01-10T02:51:58.873464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly index: 83, anomaly value: 10.0\n",
      "Anomaly index: 14, anomaly value: 9.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#import seasonal_esd as sesd\n",
    "ts = np.random.random(100)\n",
    "# Introduce artificial anomalies\n",
    "ts[14] = 9\n",
    "ts[83] = 10\n",
    "outliers_indices =seasonal_esd(ts, hybrid=True, max_anomalies=2)  # sesd.\n",
    "for idx in outliers_indices:\n",
    "\tprint(\"Anomaly index: {0}, anomaly value: {1}\".format(idx, ts[idx]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
